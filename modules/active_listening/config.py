"""
Configuration for Active Listening module.
"""

from typing import List, Optional


class ActiveListeningConfig:
    """Configuration for active listening detection."""

    # Context markers (phrases that indicate reference to previous response)
    DEFAULT_CONTEXT_MARKERS = [
        "–∫–∞–∫ –≤—ã —Å–∫–∞–∑–∞–ª–∏",
        "–≤—ã —Å–∫–∞–∑–∞–ª–∏",
        "–≤—ã —É–ø–æ–º—è–Ω—É–ª–∏",
        "–≤—ã –≥–æ–≤–æ—Ä–∏–ª–∏",
        "—É—Ç–æ—á–Ω–∏—Ç–µ",
        "–ø–æ –ø–æ–≤–æ–¥—É",
        "—ç—Ç–∏—Ö",
        "—ç—Ç–æ–π –ø—Ä–æ–±–ª–µ–º—ã",
        "—ç—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏",
        "—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏",
        "—ç—Ç–æ–≥–æ",
        "—Ç–æ–≥–æ, —á—Ç–æ –≤—ã",
        "–≤ —Å–≤—è–∑–∏ —Å —Ç–µ–º",
        "–∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ",
        "–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ",
        "–æ —á–µ–º –≤—ã",
        "—á—Ç–æ –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É"
    ]

    # English context markers
    ENGLISH_CONTEXT_MARKERS = [
        "as you said",
        "you said",
        "you mentioned",
        "you spoke about",
        "clarify",
        "regarding",
        "about that",
        "about this",
        "about the",
        "what you meant",
        "what you said"
    ]

    def __init__(
        self,
        enabled: bool = True,
        use_llm: bool = True,
        llm_fallback: bool = True,
        context_markers: Optional[List[str]] = None,
        bonus_points: int = 5,
        emoji: str = "üëÇ",
        language: str = "ru"  # "ru" or "en"
    ):
        """
        Initialize active listening configuration.

        Args:
            enabled: Enable active listening detection
            use_llm: Use LLM for detection (more accurate)
            llm_fallback: Fall back to heuristic if LLM fails
            context_markers: Custom context markers (phrases)
            bonus_points: Bonus clarity/score points for contextual questions
            emoji: Emoji for active listening indicator
            language: Language for default markers ("ru" or "en")
        """
        self.enabled = enabled
        self.use_llm = use_llm
        self.llm_fallback = llm_fallback
        self.bonus_points = bonus_points
        self.emoji = emoji
        self.language = language

        # Set context markers
        if context_markers is not None:
            self.context_markers = context_markers
        elif language == "en":
            self.context_markers = self.ENGLISH_CONTEXT_MARKERS
        else:
            self.context_markers = self.DEFAULT_CONTEXT_MARKERS

    def get_llm_prompt(self, question: str, last_response: str) -> str:
        """
        Generate LLM prompt for context detection.

        Args:
            question: User's question
            last_response: Last response from AI/client

        Returns:
            Formatted prompt for LLM
        """
        if self.language == "en":
            return f"""Determine if the following question references or uses information from the previous response.

Previous response:
{last_response}

Current question:
{question}

Does the question reference specific facts, numbers, or information from the previous response?
Answer with ONLY "yes" or "no"."""
        else:
            return f"""–û–ø—Ä–µ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ —Ñ–∞–∫—Ç—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.

–ü—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç:
{last_response}

–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å:
{question}

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏ –≤–æ–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞?
–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û "yes" –∏–ª–∏ "no"."""
